# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/Touseeqkh/c8a00c6a91dcfe624d8c6732696d004f/app.ipynb
"""

from google.colab import drive
drive.mount('/content/drive')

import joblib

model = joblib.load("/content/rf_model.joblib")
scaler = joblib.load("/content/scaler.joblib")
feature_cols = joblib.load("/content/feature_cols.joblib")

print("Model:", type(model))
print("Scaler:", type(scaler))
print("Number of features:", len(feature_cols))
print("Features:", feature_cols)

import pandas as pd
import numpy as np

# Create a dummy input to test shape
dummy_input = pd.DataFrame(
    np.zeros((1, len(feature_cols))),
    columns=feature_cols
)

scaled_input = scaler.transform(dummy_input)
prediction = model.predict(scaled_input)

prediction

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import joblib
# import pandas as pd
# import numpy as np
# 
# # Load model and preprocessing tools
# model = joblib.load("rf_model.joblib")
# scaler = joblib.load("scaler.joblib")
# feature_cols = joblib.load("feature_cols.joblib")
# 
# st.title("Leachate Prediction Application")
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.header("Rock Characteristics")
# 
# user_inputs = {}
# for feature in feature_cols:
#     user_inputs[feature] = st.number_input(
#         label=feature,
#         value=0.0
#     )

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# input_df = pd.DataFrame([user_inputs])
# input_scaled = scaler.transform(input_df)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.header("Sequence of Events S")
# 
# events_text = st.text_area(
#     "Enter one event per line",
#     "Rainfall\nTemperature Increase\nAcid Exposure"
# )
# 
# events = events_text.split("\n")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# if st.button("Run Prediction"):
#     st.subheader("Predictions After Each Event")
# 
#     current_state = input_scaled.copy()
# 
#     for i, event in enumerate(events):
#         prediction = model.predict(current_state)[0]
# 
#         st.write(f"After event {i+1} ({event}): {prediction:.4f}")
# 
#         # Optional: simulate small change after each event
#         current_state = current_state * 1.01

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.subheader("Explanation")
# 
# importances = model.feature_importances_
# importance_df = pd.DataFrame({
#     "Feature": feature_cols,
#     "Importance": importances
# }).sort_values(by="Importance", ascending=False)
# 
# st.write("Most influential features:")
# st.dataframe(importance_df)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.header("Rock Selection")
# 
# predefined_rocks = {
#     "Custom": None,
#     "Basalt": {f: 0.3 for f in feature_cols},
#     "Granite": {f: 0.2 for f in feature_cols},
#     "Limestone": {f: 0.4 for f in feature_cols},
# }
# 
# rock_choice = st.selectbox(
#     "Select a rock type",
#     list(predefined_rocks.keys())
# )

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.subheader("Rock Characteristics")
# 
# user_inputs = {}
# 
# for feature in feature_cols:
#     default_value = 0.0
#     if rock_choice != "Custom":
#         default_value = predefined_rocks[rock_choice][feature]
# 
#     user_inputs[feature] = st.number_input(
#         label=feature,
#         value=float(default_value)
#     )

def apply_event(state, event):
    event = event.lower()

    if "rain" in event:
        return state * 1.05
    elif "acid" in event:
        return state * 1.10
    elif "temperature" in event or "heat" in event:
        return state * 1.03
    else:
        return state

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# if st.button("Run Prediction"):
#     st.subheader("Leachate Predictions")
# 
#     input_df = pd.DataFrame([user_inputs])
#     current_state = scaler.transform(input_df)
# 
#     for i, event in enumerate(events):
#         prediction = model.predict(current_state)[0]
# 
#         st.write(f"After event {i+1} ({event}): **{prediction:.4f}**")
# 
#         current_state = apply_event(current_state, event)
#

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# st.subheader("Explanation")
# 
# st.write(
#     """
#     The predictions are generated using a Random Forest model trained on
#     scaled rock characteristics. After each event, the input state is updated
#     to simulate environmental influence on leachate formation.
#     """
# )

# Commented out IPython magic to ensure Python compatibility.
# %%writefile -a app.py
# import matplotlib.pyplot as plt
# 
# importances = model.feature_importances_
# importance_df = pd.DataFrame({
#     "Feature": feature_cols,
#     "Importance": importances
# }).sort_values(by="Importance", ascending=False)
# 
# st.write("Feature importance used by the model:")
# 
# fig, ax = plt.subplots()
# ax.barh(importance_df["Feature"], importance_df["Importance"])
# ax.invert_yaxis()
# st.pyplot(fig)

!streamlit run app.py

